---
title: 爬虫学习笔记 
tags: 爬虫,Python
grammar_cjkRuby: true
---


## 评估网页数量
可以利用百度或者Google

    site:www.cnblogs.com
 >Google可以搜索子目录
 
 ## 不重复爬取
 原理就是标记URL，之后爬取新的页面对比URL
 > 1. MD5处理URL后存储
 > 2. 利用Bit-Map方法建立BitSet，对URL进行哈希映射
 > 3. 布隆过滤器，pybloomfilter
## 网站地图
爬虫爬取网站之前首先访问网站根目录下的Robots.txt
根据`Robots.txt`判断可以爬取哪些内容
利用`sitemap.xml`分析网站规模
## 正则表达式

    import re
    findall(pattern, string, flags=0)


## 使用Chrome
在Chrome中`检查`网页，
可以在`Console`里执行命令查看节点
例如：

    document.childNodes
    document.getRootNode()
    document.getRootNode().childNodes
    document.getRootNode().childNodes[1]
    document.getRootNode().childNodes[1].childNodes[1]
    document.getElementsByClassName('J-p-990687')[0]	# 京东价格元素
    document.getElementsByClassName('price J-p-3418627')[0].innerHTML	# 获取价格 
来一直遍历HTML文档结构

## 网页的关键内容
- Title 网页的标题
- Content Title 正文标题
- Content 正文部分
- Anchor 内部锚点（百度百科跳段）
- Link 外部链接




















