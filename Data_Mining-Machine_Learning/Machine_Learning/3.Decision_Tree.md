# 决策树

`k-近邻算法` 最大的缺点是无法给出数据的内在含义   
`决策树` 的主要优势在于数据形式非常容易理解  

> 优点：计算复杂度不高，输出结果易于理解，对中间值缺失不敏感，可以处理不相关特征数据
> 缺点：可能会产生过度匹配问题  
> 适用：数值型和标称型

决策树算法流程:  

1. 计算给定数据集的香农熵，熵越高代表混合的数据越多  
2. 按照给定特征划分数据集  
3. 根据香农熵选择最好的数据集划分方式
4. 递归构建决策树  
5. 根据决策树绘制树形图  

为了减少过度匹配的问题，可以剪裁决策树，去掉一些不必要的叶子节点，或者把它并入其他叶子节点  
